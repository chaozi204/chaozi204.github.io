<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hive | 超子博客]]></title>
  <link href="http://chaozi204.github.io/blog/categories/hive/atom.xml" rel="self"/>
  <link href="http://chaozi204.github.io/"/>
  <updated>2015-01-10T23:15:23+08:00</updated>
  <id>http://chaozi204.github.io/</id>
  <author>
    <name><![CDATA[超子]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[利用RCFile的特性，提供压缩算法的压缩率]]></title>
    <link href="http://chaozi204.github.io/blog/2015/01/08/rcfile-assistant-compression/"/>
    <updated>2015-01-08T18:37:59+08:00</updated>
    <id>http://chaozi204.github.io/blog/2015/01/08/rcfile-assistant-compression</id>
    <content type="html"><![CDATA[<pre><code>最近公司集群的存储空间过于紧张，一度低于5% 。集群空间一下子成为了非常严肃的系统瓶颈。
无意中同事发现他的同一份业务数据使用不同的压缩产生了非常大的差异。 一个使用LZO压缩的，一份使用hadoop默认的Deflate压缩的。
经过我们分析，得出了利用rcfile存储特性（行列混合存储）可以帮我们节省大量的存储空间，当然这个是非常巧合的，因为日志记录相似性非常高。
利用distribute by + sort by 将非常类似的数据存储到同一个reduce中，再利用rcfile混合存储+压缩算法，就可以大大节省了存储空间。
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive正则匹配中文问题]]></title>
    <link href="http://chaozi204.github.io/blog/2014/11/29/hive-chinese/"/>
    <updated>2014-11-29T17:34:37+08:00</updated>
    <id>http://chaozi204.github.io/blog/2014/11/29/hive-chinese</id>
    <content type="html"><![CDATA[<p>利用Hive的正则匹配中文时需要注意：</p>

<ul>
<li>中文的字符集合为[\u4e00-\u9fa5]</li>
<li>但是hive在hive执行中会被转义，因此需要增加一次java的转义字符才能够正确使用</li>
</ul>


<p>例如：
<code>select title from vid_title where type='my' and title rlike '^[\\\u4e00-\\\u9fa5]{1,2}$'</code></p>
]]></content>
  </entry>
  
</feed>
