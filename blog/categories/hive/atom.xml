<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hive | 超子博客]]></title>
  <link href="http://chaozi204.github.io/blog/categories/hive/atom.xml" rel="self"/>
  <link href="http://chaozi204.github.io/"/>
  <updated>2015-08-17T14:57:34+08:00</updated>
  <id>http://chaozi204.github.io/</id>
  <author>
    <name><![CDATA[超子]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[利用RCFile的特性提高压缩率]]></title>
    <link href="http://chaozi204.github.io/blog/2015/01/08/rcfile-assistant-compression/"/>
    <updated>2015-01-08T18:37:59+08:00</updated>
    <id>http://chaozi204.github.io/blog/2015/01/08/rcfile-assistant-compression</id>
    <content type="html"><![CDATA[<pre><code>最近公司集群的存储空间过于紧张，一度低于5% 。集群空间一下子成为了集群瓶颈。再申请扩容无望的情况下，我们不得不着手于通过业务节省空间，
或者强制进行删除文件。
同事无意中发现他的一份业务数据采用lzo + rcfile压缩后，压缩率超高，压缩前3G，压缩后200M。这种压缩率让我们感觉到异常，于是调查原因发现：
1. 日志相似性比较（这是业务本身的特性）
2. 生成结果数据是，利用李distribute by + sort by的hive特性，将相似的记录放在同一个reduce中，并根据特性字段排序
3. 利用rcfile的行列混合存储特性，就可以完成非常高的压缩率了
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive正则匹配中文问题]]></title>
    <link href="http://chaozi204.github.io/blog/2014/11/29/hive-chinese/"/>
    <updated>2014-11-29T17:34:37+08:00</updated>
    <id>http://chaozi204.github.io/blog/2014/11/29/hive-chinese</id>
    <content type="html"><![CDATA[<p>利用Hive的正则匹配中文时需要注意：</p>

<ul>
<li>中文的字符集合为[\u4e00-\u9fa5]</li>
<li>但是hive在hive执行中会被转义，因此需要增加一次java的转义字符才能够正确使用</li>
</ul>


<p>例如：
<code>select title from vid_title where type='my' and title rlike '^[\\\u4e00-\\\u9fa5]{1,2}$'</code></p>
]]></content>
  </entry>
  
</feed>
