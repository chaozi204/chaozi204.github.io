
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Hadoop V2 Snappy 安装及部署 - 超子博客</title>
  <meta name="author" content="超子">

  
  <meta name="description" content="最近同事有需求要使用在hadoop 2.5.1的集群上使用snappy压缩。因为之前没有使用过snappy，所以没有在现有的集群上配置相关信息，于是乎就在官方和google查了一下相关的配置信息。之所以写这篇文章，主要是因为网上发的文章（尤其是中国的某些网站）的内容不靠谱，没有仔细阅读文档， &hellip;">
  <meta name="keywords" content="hadoop snappy install">

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://chaozi204.github.io/blog/2015/11/10/hadoop-v2-snappy-install">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="超子博客" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">超子博客</a></h1>
  
    <h2>好记性，不如烂笔头</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://wen.lu/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:chaozi204.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Hadoop V2 Snappy 安装及部署</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-11-10T11:19:54+08:00'><span class='date'><span class='date-month'>Nov</span> <span class='date-day'>10</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>11:19 am</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><blockquote><p>最近同事有需求要使用在hadoop 2.5.1的集群上使用snappy压缩。因为之前没有使用过snappy，所以没有在现有的集群上配置相关信息，于是乎就在官方和google查了一下相关的配置信息。之所以写这篇文章，主要是因为网上发的文章（尤其是中国的某些网站）的内容不靠谱，没有仔细阅读文档，就随便写一些不经过实践的文章来忽悠大家，导致大家如果根据他们的方式来安装和使用，可能会导致莫名其妙的问题。闲话不说了，写下我的操作过程</p></blockquote>

<h5>1 安装 snappy lib库</h5>

<p>snappy是google的开源项目，目前代码已经迁移到github上，
地址为：<a href="http://google.github.io/snappy/">http://google.github.io/snappy/</a> 。不过比较操蛋的事情是，git上的代码里面没有configure文件，导致我这种c菜鸟不会整了，于是只能在中国的不靠谱网站-csdn找到一个版本，比如我现在用的1.1.2版本。剩下的就是编译安装snappy库了，过程如下(前提你已经安装了相关的依赖库，这里不罗嗦)：</br></p>

<pre><code>./configure
make
make install
</code></pre>

<p>这样默认安装snappy库到/usr/local/lib下
 <!-- more --></p>

<h5>2 重新编译hadoop</h5>

<p>编译前建议仔细阅读Hadoop的BUILDING文件，使用如下命令进行编译</p>

<pre><code>mvn clean package -Pdist,native -DskipTests -Dtar  -Drequire.snappy  -Dbundle.snappy -Dsnappy.lib=/usr/local/lib
</code></pre>

<p>利用这个命令编译后的hadoop就会将snappy的native库拷贝到了hadoop/lib/native下面了，并且libhadoop的so文件中也会携带了相关的信息。</p>

<h5>3 部署</h5>

<ol>
<li>将新编译的hadoop native库下的内容替换线上的。</li>
<li>修改hadoop的配置属性，增加hadoop对snappy encode和decode类的配置
 <code>
 &lt;property&gt;
   &lt;name&gt;io.compression.codecs&lt;/name&gt;
   &lt;value&gt;
org.apache.hadoop.io.compress.DefaultCodec,
org.apache.hadoop.io.compress.GzipCodec,
org.apache.hadoop.io.compress.BZip2Codec,
com.hadoop.compression.lzo.LzoCodec,
com.hadoop.compression.lzo.LzopCodec,
org.apache.hadoop.io.compress.SnappyCodec
  &lt;/value&gt;
&lt;/property&gt;
</code></li>
<li>重启集群</li>
<li>测试snappy。方法很简单，找一个snappy的文件，利用hadoop fs -text如果能打开则证明安装完成。或者使用hadoop的命令 hadoop checknative -a</li>
</ol>


<h5>4 解疑答惑</h5>

<ol>
<li>网上很多文章说还要安装hadoop-snappy，我想说的是，这个是针对hadoop v1的，因为hadoop v2中已经携带了snappy的decode和encode代码了。所以根本不需要安装这个jar，而且安装后使用hadoop checknative -a会报错，错误如下：</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bzip2.Bzip2Factory: Failed to load/initialize native-bzip2 library system-native, will use pure-Java version15/11/09 18:14:12 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib libraryException in thread "main" java.lang.NoSuchMethodError: org.apache.hadoop.io.compress.SnappyCodec.isNativeCodeLoaded()Z        at org.apache.hadoop.util.NativeLibraryChecker.main(NativeLibraryChecker.java:82)</span></code></pre></td></tr></table></div></figure>


<ol>
<li>如果snappy为安装好或安装成功，有可能出现的一种问题如下：</li>
</ol>


<p><code>java.lang.RuntimeException: native snappy library not available: this version of libhadoop was built without snappy support.        at org.apache.hadoop.io.compress.SnappyCodec.checkNativeCodeLoaded(SnappyCodec.java:64)        at org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:201)        at org.apache.hadoop.io.compress.SnappyCodec.createInputStream(SnappyCodec.java:161)        at org.apache.hadoop.fs.shell.Display$Text.getInputStream(Display.java:150)        at org.apache.hadoop.fs.shell.Display$Cat.processPath(Display.java:98)        at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:306)        at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:278)        at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:260)        at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:244)        at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:190)        at org.apache.hadoop.fs.shell.Command.run(Command.java:154)        at org.apache.hadoop.fs.FsShell.run(FsShell.java:287)        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)        at org.apache.hadoop.fs.FsShell.main(FsShell.java:340)
</code></p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">超子</span></span>

      




<time class='entry-date' datetime='2015-11-10T11:19:54+08:00'><span class='date'><span class='date-month'>Nov</span> <span class='date-day'>10</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>11:19 am</span></time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/hadoop/'>hadoop</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2015/11/06/hive-udf-deploy/" title="Previous Post: hive udf 部署方式小结">&laquo; hive udf 部署方式小结</a>
      
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
<h1>Recent Comments</h1>
<ul class="ds-recent-comments" data-num-items="10" data-show-avatars="0" data-show-time="0" data-show-title="0" data-show-admin="0" data-excerpt-length="18"></ul>

</section>


  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - 超子 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
