<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hadoop | 超子博客]]></title>
  <link href="http://chaozi204.github.io/blog/categories/hadoop/atom.xml" rel="self"/>
  <link href="http://chaozi204.github.io/"/>
  <updated>2015-11-06T19:20:22+08:00</updated>
  <id>http://chaozi204.github.io/</id>
  <author>
    <name><![CDATA[超子]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Yarn 日志聚集权限警告]]></title>
    <link href="http://chaozi204.github.io/blog/2015/08/24/log-aggregation-permission-warning/"/>
    <updated>2015-08-24T18:04:00+08:00</updated>
    <id>http://chaozi204.github.io/blog/2015/08/24/log-aggregation-permission-warning</id>
    <content type="html"><![CDATA[<h3>问题描述</h3>

<p>集群中所有的nodemanager节点机器总是会报出警告信息</p>

<blockquote><p>警告信息：
2015-07-29 00:44:57,785 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService: Remote Root Log Dir [/yarn-logs] already exist, but with incorrect permissions. Expected: [rwxrwxrwt], Found: [rwxr-xr-x]. The cluster may have problems with multiple users.</p></blockquote>

<p>从警告的内容来看，似乎是目录的权限不匹配导致的，为了防止这个警告产生对集群的影响，于是排查本异常产生的原因。</p>

<!-- more -->


<h3>问题原因</h3>

<p>产生警告的类为 LogAggregationService.java , 其中产生警告的代码为
<code>java
 void verifyAndCreateRemoteLogDir(Configuration conf) {
  // Checking the existence of the TLD
  FileSystem remoteFS = null;
  try {
    remoteFS = getFileSystem(conf);
  } catch (IOException e) {
    throw new YarnRuntimeException("Unable to get Remote FileSystem instance", e);
  }
  boolean remoteExists = true;
  try {
    FsPermission perms =
        remoteFS.getFileStatus(this.remoteRootLogDir).getPermission();
    if (!perms.equals(TLDIR_PERMISSIONS)) {
      LOG.warn("Remote Root Log Dir [" + this.remoteRootLogDir
          + "] already exist, but with incorrect permissions. "
          + "Expected: [" + TLDIR_PERMISSIONS + "], Found: [" + perms
          + "]." + " The cluster may have problems with multiple users.");
    }
  } catch (FileNotFoundException e) {
    remoteExists = false;
  } catch (IOException e) {
    throw new YarnRuntimeException(
        "Failed to check permissions for dir ["
            + this.remoteRootLogDir + "]", e);
  }
  if (!remoteExists) {
    LOG.warn("Remote Root Log Dir [" + this.remoteRootLogDir
        + "] does not exist. Attempting to create it.");
    try {
      Path qualified =
          this.remoteRootLogDir.makeQualified(remoteFS.getUri(),
              remoteFS.getWorkingDirectory());
      remoteFS.mkdirs(qualified, new FsPermission(TLDIR_PERMISSIONS));
      remoteFS.setPermission(qualified, new FsPermission(TLDIR_PERMISSIONS));
    } catch (IOException e) {
      throw new YarnRuntimeException("Failed to create remoteLogDir ["
          + this.remoteRootLogDir + "]", e);
    }
  }
}
</code></p>

<p>代码中的第11-17行中就是这个警告产生的过程。从代码不难看出，这个警告不会对系统运行产生影响，也不会给系统造成多大的负担。
从代码的逻辑中，我们可以看出hadoop希望我们将聚合日志的目录（就是配置属性yarn.nodemanager.remote-app-log-dir指定的目录）设置为权限01777（其中1权限代码sticky bit），权限参考HDFS 权限说明 。而实际我们的集群因为保证完全的用户隔离和写安全，将日志聚合目录修改为了755权限（我们会单独为每个新用户创建相应的聚合目录），因此导致hadoop期望的权限和我们设置的权限不匹配，从而导致了问题的产生。</p>

<h3>解决方法</h3>

<p>解决方法1： 如果对系统的安全性要求没有特别的要求，可以完全将日志聚合目录的权限按hadoop的要求修改为01777权限，这个问题自然解决。</p>

<p>解决方法2：在创建新用户的情况下，可以手动给每个用户创建对应的聚合目录，也不会影响聚合功能的使用。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Task读取HDFS数据导致任务失败或延迟]]></title>
    <link href="http://chaozi204.github.io/blog/2014/11/25/confession/"/>
    <updated>2014-11-25T23:00:37+08:00</updated>
    <id>http://chaozi204.github.io/blog/2014/11/25/confession</id>
    <content type="html"><![CDATA[<h3>问题描述</h3>

<ul>
<li><p>Hadoop Job在执行时非常缓慢（hadoop-1.0.0 和 hadoop-2.5.0集群中都有），且很多Map任务或reduce任务因为超时被kill掉，异常信息如下：
<code>Task attempt_201406261559_894052_m_000269_1 failed to report status for 602 seconds. Killing!</code></p></li>
<li><p>任务卡在初始化的过程中，也就是Map和Reduce的setup方法中
<code>protected void setup(Context context ) throws IOException, InterruptedException { }
</code></p></li>
<li>任务有些成功有些被kill，大部分情况下job最终执行是成功，只是比较耗时</li>
</ul>


<!-- more -->


<h3>问题分析及排查</h3>

<ul>
<li>首先排查GC导致的问题，检查其中几个任务的gc情况就可以得出是不是GC引起的</li>
<li>因为任务是因为超时被kill的，也就是说任务在10分钟左右都没有进度，且任务的状态是在RUNNING状态，也就是说任务要么卡在setup初始化中，要么是卡在map方法或reduce方法中比较耗时的操作</li>
<li>检查用户代码，主要查看setup方法和任务比较耗时的map或reduce方法</li>
<li><p>发现在setup方法中，会去读取hdfs文件，文件大小在100M左右
<code>java
public static String read(String filePath) throws IOException{  
  Configuration config = new Configuration();
  FSDataInputStream in = null;
  String fileName = filePath;
  StringBuffer rv=new StringBuffer();
  FileSystem hdfs = FileSystem.get(config);
  in = hdfs.open(new Path(fileName));
  String aline = null;
  BufferedReader bufread= new BufferedReader(new InputStreamReader(in, "UTF-8"));
  while((aline=bufread.readLine())!=null){
      rv.append(aline+"\n");}
  in.close();
  return rv.toString();
}
</code></p></li>
<li><p>此时开始怀疑是不是因为读取文件而导致这个问题呢。于是分析计算，总计2400 Map个，3个文件的备份，每个备份要负责800个任务的读取操作，假设网络带宽为100M跑满，也就是1秒中最多只能给1个map输送数据，这样全部完成需要800秒，超过了10分钟，也就是任务被kill的原因（以上分析完全是理想的情况下，实际情况更复杂），这是去查看cache的文件在机器的备份情况，然后通过ganglia查看机器当时的网络消费（的确是跑满了网络带宽，而且持续时间超过了10分钟），因此判断是因为网络堵塞导致任务失败.</p></li>
</ul>


<h3>解决方法</h3>

<ul>
<li>最好使用DistributeCache来代替直接读取hdfs文件的操作，这样不仅可以接受网络带宽，还能减少任务初始化的时间，减少因为本任务对其他任务的影响</li>
<li>次之方法是将文件的备份数增多，但是全部的网络消耗并没有节省，但是能够保证任务执行</li>
</ul>

]]></content>
  </entry>
  
</feed>
